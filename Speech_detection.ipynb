{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech_detection_Assignment (RadhikaRathi).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwoTWIysaNmc"
      },
      "source": [
        "# <font color='red'> Spoken Digit Recognition</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPO3mjDDaNmf"
      },
      "source": [
        "\n",
        "In this notebook, You will do Spoken Digit Recognition. \n",
        "\n",
        "Input - speech signal, output - digit number\n",
        "\n",
        "\n",
        "\n",
        "It contains  \n",
        "\n",
        "1. Reading the dataset. and Preprocess the data set. Detailed instrctions are given below. You have to write the code in the same cell which contains the instrction. \n",
        "2. Training the LSTM with RAW data\n",
        "3. Converting to spectrogram and Training the LSTM network\n",
        "4. Creating the augmented data and doing step 2 and 3 again.  \n",
        "\n",
        "<font size=5>Instructions:</font>\n",
        "\n",
        "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. If you manipulate any, it will be considered as plagiarised. \n",
        "    \n",
        "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
        "    \n",
        "    3. Please return outputs in the same format what we asked. Eg. Don't return List of we are asking for a numpy array.\n",
        "    \n",
        "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
        "    \n",
        "    5. We are giving instructions at each section if necessary, please follow them. \n",
        "\n",
        "<font size=5>Every Grader function has to return True. </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qGuPcj-aNmh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import seaborn as sns\n",
        "##if you need any imports you can do that here. "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nArEnMT0EB5b",
        "outputId": "931b131b-d671-4f6e-9508-838f9f2e7af2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdhFzGK1aNmo"
      },
      "source": [
        "We shared recordings.zip, please unzip those. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDBcl_PUaNmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ca49d0-0034-4cc1-cdb1-073777dde7c5"
      },
      "source": [
        "#read the all file names in the recordings folder given by us\n",
        "#(if you get entire path, it is very useful in future)\n",
        "#save those files names as list in \"all_files\"\n",
        "r = \"drive/My Drive/content/recordings/\"\n",
        "all_files=[]\n",
        "for a in os.listdir(r):\n",
        "    all_files.append(os.path.join(r,a))\n",
        "print(\"No. of audio files:\",len(all_files))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of audio files: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NYYpfqoaNmv"
      },
      "source": [
        "<font size=4>Grader function 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oJSOmYBaNmx",
        "outputId": "38a2df2d-8a7b-414a-b8d2-d4ce33be746b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def grader_files():\n",
        "    temp = len(all_files)==2000\n",
        "    temp1 = all([x[-3:]==\"wav\" for x in all_files])\n",
        "    temp = temp and temp1\n",
        "    return temp\n",
        "grader_files()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhvSIN6raNm3"
      },
      "source": [
        "Create a dataframe(name=df_audio) with two columns(path, label).   \n",
        "You can get the label from the first letter of name.  \n",
        "Eg: 0_jackson_0 --> 0  \n",
        "0_jackson_43 --> 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZbhCvvRPPMw"
      },
      "source": [
        "## Exploring the sound dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilJsqdhhPMed"
      },
      "source": [
        "#It is a good programming practise to explore the dataset that you are dealing with. This dataset is unique in itself because it has sounds as input\n",
        "#https://colab.research.google.com/github/Tyler-Hilbert/AudioProcessingInPythonWorkshop/blob/master/AudioProcessingInPython.ipynb\n",
        "#visualize the data and write code to play 2-3 sound samples in the notebook for better understanding.\n",
        "#please go through the following reference video https://www.youtube.com/watch?v=37zCgCdV468"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX_umjikPy5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "fee3d833-e47e-4fff-bb73-2c8ac6921577"
      },
      "source": [
        "import IPython\n",
        "IPython.display.Audio(all_files[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" >\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA0nAtjbQLmu"
      },
      "source": [
        "## Creating dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWP6vXBeaNm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8396f8cb-514c-4629-f75d-8d3a27fbfdb3"
      },
      "source": [
        "#Create a dataframe(name=df_audio) with two columns(path, label).   \n",
        "#You can get the label from the first letter of name.  \n",
        "#Eg: 0_jackson_0 --> 0  \n",
        "#0_jackson_43 --> 0\n",
        "df_audio = pd.DataFrame({\"path\":all_files,\"label\":[b[len(r)] for b in all_files]})\n",
        "df_audio.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                path label\n",
              "0  drive/My Drive/content/recordings/5_jackson_0.wav     5\n",
              "1  drive/My Drive/content/recordings/5_jackson_1.wav     5\n",
              "2  drive/My Drive/content/recordings/5_jackson_10...     5\n",
              "3  drive/My Drive/content/recordings/5_jackson_11...     5\n",
              "4  drive/My Drive/content/recordings/5_jackson_12...     5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfce7b34-7113-4e97-81ea-09dfe6f635d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drive/My Drive/content/recordings/5_jackson_0.wav</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drive/My Drive/content/recordings/5_jackson_1.wav</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drive/My Drive/content/recordings/5_jackson_10...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drive/My Drive/content/recordings/5_jackson_11...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drive/My Drive/content/recordings/5_jackson_12...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfce7b34-7113-4e97-81ea-09dfe6f635d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfce7b34-7113-4e97-81ea-09dfe6f635d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfce7b34-7113-4e97-81ea-09dfe6f635d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZpuaGuJaNm8",
        "outputId": "d3748286-f42a-4bd2-e865-b09d75ba3580",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#info\n",
        "df_audio.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   path    2000 non-null   object\n",
            " 1   label   2000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOKpYJ_LaNnD"
      },
      "source": [
        "<font size=4>Grader function 2 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q8r_T8-aNnE",
        "outputId": "31b06c7f-75f4-45f0-df00-efe301dbc3a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def grader_df():\n",
        "    flag_shape = df_audio.shape==(2000,2)\n",
        "    flag_columns = all(df_audio.columns==['path', 'label'])\n",
        "    list_values = list(df_audio.label.value_counts())\n",
        "    flag_label = len(list_values)==10\n",
        "    flag_label2 = all([i==200 for i in list_values])\n",
        "    final_flag = flag_shape and flag_columns and flag_label and flag_label2\n",
        "    return final_flag\n",
        "grader_df()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlfssCc3aNnL"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "df_audio = shuffle(df_audio, random_state=33)#don't change the random state"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ448aENaNnR"
      },
      "source": [
        "<pre><font size=4>Train and Validation split</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSPy-Ln6aNnS"
      },
      "source": [
        "#split the data into train and validation and save in X_train, X_test, y_train, y_test\n",
        "#use stratify sampling\n",
        "#use random state of 45\n",
        "#use test size of 30%\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_audio[\"path\"],df_audio[\"label\"],test_size=0.3,stratify=df_audio[\"label\"],\n",
        "                                                   random_state=45)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ukPvoW2SiFc",
        "outputId": "ea632e2d-d3a4-4c53-e996-3cfa35f34644"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1400,), (600,), (1400,), (600,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPK3sbzUaNnW"
      },
      "source": [
        "<font size=4>Grader function 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chZzntKUaNnX",
        "outputId": "aacea031-2f8b-4002-8f85-0c3174f8bbcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def grader_split():\n",
        "    flag_len = (len(X_train)==1400) and (len(X_test)==600) and (len(y_train)==1400) and (len(y_test)==600)\n",
        "    values_ytrain = list(y_train.value_counts())\n",
        "    flag_ytrain = (len(values_ytrain)==10) and (all([i==140 for i in values_ytrain]))\n",
        "    values_ytest = list(y_test.value_counts())\n",
        "    flag_ytest = (len(values_ytest)==10) and (all([i==60 for i in values_ytest]))\n",
        "    final_flag = flag_len and flag_ytrain and flag_ytest\n",
        "    return final_flag\n",
        "grader_split()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGhh-39vaNnb"
      },
      "source": [
        "<pre><font size=4>Preprocessing</font>\n",
        "\n",
        "All files are in the \"WAV\" format. We will read those raw data files using the librosa</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i99JacQSaNnc"
      },
      "source": [
        "sample_rate = 22050\n",
        "def load_wav(x, get_duration=True):\n",
        "    '''This return the array values of audio with sampling rate of 22050 and Duration'''\n",
        "    #loading the wav file with sampling rate of 22050\n",
        "    samples, sample_rate = librosa.load(x, sr=22050)\n",
        "    if get_duration:\n",
        "        duration = librosa.get_duration(samples, sample_rate)\n",
        "        return [samples, duration]\n",
        "    else:\n",
        "        return samples"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = load_wav(all_files[0])\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myzXhDx6S4Gm",
        "outputId": "af30ac5e-f9ba-418b-c66a-b0d00c6eacd5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.01647412, -0.02081497, -0.01905589, ..., -0.00874536,\n",
              "        -0.00633125,  0.        ], dtype=float32), 0.42426303854875286]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(z[0]),0.42426303854875286*22050"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyIU861FS-ed",
        "outputId": "b29e4e76-e8c4-4a25-a8dd-07a78b024bba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9355, 9355.0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx97f8GGaNnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365e1e33-754c-48c0-ed5d-d783e430a07e"
      },
      "source": [
        "#use load_wav function that was written above to get every wave. \n",
        "#save it in X_train_processed and X_test_processed\n",
        "# X_train_processed/X_test_processed should be dataframes with two columns(raw_data, duration) with same index of X_train/y_train\n",
        "xtr_p = [load_wav(x)[0] for x in X_train]\n",
        "xte_p = [load_wav(x)[0] for x in X_test]\n",
        "xtr_d = [load_wav(x)[1] for x in X_train]\n",
        "xte_d = [load_wav(x)[1] for x in X_test]\n",
        "\n",
        "len(xtr_p),len(xte_p),len(xtr_d),len(xte_d)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 600, 1400, 600)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_processed = pd.DataFrame({\"raw_data\":xtr_p,\"duration\":xtr_d})\n",
        "X_test_processed = pd.DataFrame({\"raw_data\":xte_p,\"duration\":xte_d})"
      ],
      "metadata": {
        "id": "3ay2n8jBXPlF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_processed.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MxQ01wBOXWne",
        "outputId": "1bc2cf37-03ea-4ce0-89e6-18ac658b21ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            raw_data  duration\n",
              "0  [-0.0002015104, -8.0844686e-05, -3.0828054e-05...  0.222630\n",
              "1  [-0.0004445809, -0.00057286676, -0.00061524694...  0.352653\n",
              "2  [-0.0008351869, -0.00088791404, -0.00056625315...  0.396644\n",
              "3  [-0.01165101, -0.015677933, -0.01861837, -0.02...  0.359501\n",
              "4  [0.009092156, 0.010865747, 0.011127, 0.0105336...  0.664762"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-318ecd60-49f6-4377-81d6-8814cf0b885f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_data</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.0002015104, -8.0844686e-05, -3.0828054e-05...</td>\n",
              "      <td>0.222630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.0004445809, -0.00057286676, -0.00061524694...</td>\n",
              "      <td>0.352653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.0008351869, -0.00088791404, -0.00056625315...</td>\n",
              "      <td>0.396644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.01165101, -0.015677933, -0.01861837, -0.02...</td>\n",
              "      <td>0.359501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.009092156, 0.010865747, 0.011127, 0.0105336...</td>\n",
              "      <td>0.664762</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-318ecd60-49f6-4377-81d6-8814cf0b885f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-318ecd60-49f6-4377-81d6-8814cf0b885f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-318ecd60-49f6-4377-81d6-8814cf0b885f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rN-16-GDXdgI",
        "outputId": "587f2995-1c53-45ef-809d-de83fe48c750"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            raw_data  duration\n",
              "0  [0.00012860933, 0.00022954274, 0.00024249818, ...  0.239909\n",
              "1  [-0.010588735, -0.009987316, -0.00675926, -0.0...  0.371791\n",
              "2  [-0.00036598003, -0.00020610698, 4.5755176e-05...  0.306893\n",
              "3  [-0.00018873895, -0.00021362105, -0.0001426177...  0.161769\n",
              "4  [-0.00984854, -0.013759347, -0.014475624, -0.0...  0.422902"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a9eb8a3-1278-4c7b-9b62-0dd720652cf8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_data</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.00012860933, 0.00022954274, 0.00024249818, ...</td>\n",
              "      <td>0.239909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.010588735, -0.009987316, -0.00675926, -0.0...</td>\n",
              "      <td>0.371791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.00036598003, -0.00020610698, 4.5755176e-05...</td>\n",
              "      <td>0.306893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.00018873895, -0.00021362105, -0.0001426177...</td>\n",
              "      <td>0.161769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.00984854, -0.013759347, -0.014475624, -0.0...</td>\n",
              "      <td>0.422902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a9eb8a3-1278-4c7b-9b62-0dd720652cf8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a9eb8a3-1278-4c7b-9b62-0dd720652cf8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a9eb8a3-1278-4c7b-9b62-0dd720652cf8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duQZPQevaNno",
        "outputId": "986d5696-ddbc-49a1-ebd1-9fb414fa51cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "#plot the histogram of the duration for trian\n",
        "sns.histplot(X_train_processed[\"duration\"])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b7495a210>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLhm1AqaNny",
        "outputId": "d37e100b-1a47-49a0-ed34-b5f459825fb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#print 0 to 100 percentile values with step size of 10 for train data duration. \n",
        "for i in range(0,101,10):\n",
        "    print('{}th percentile of duration is '.format(i),np.percentile(X_train_processed[\"duration\"],i))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0th percentile of duration is  0.1435374149659864\n",
            "10th percentile of duration is  0.26225396825396824\n",
            "20th percentile of duration is  0.298140589569161\n",
            "30th percentile of duration is  0.33127437641723356\n",
            "40th percentile of duration is  0.3572517006802721\n",
            "50th percentile of duration is  0.388843537414966\n",
            "60th percentile of duration is  0.4164172335600907\n",
            "70th percentile of duration is  0.4444671201814059\n",
            "80th percentile of duration is  0.48358276643990933\n",
            "90th percentile of duration is  0.5549297052154195\n",
            "100th percentile of duration is  2.282766439909297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSlVQh4CaNn2",
        "outputId": "f314ab8f-53e6-4142-eafa-e124af2820be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##print 90 to 100 percentile values with step size of 1. \n",
        "for i in range(90,101,1):\n",
        "    print('{}th percentile of duration is '.format(i),np.percentile(X_train_processed[\"duration\"],i))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90th percentile of duration is  0.5549297052154195\n",
            "91th percentile of duration is  0.5669832199546486\n",
            "92th percentile of duration is  0.5790349206349207\n",
            "93th percentile of duration is  0.5902512471655333\n",
            "94th percentile of duration is  0.6078993197278911\n",
            "95th percentile of duration is  0.6210544217687075\n",
            "96th percentile of duration is  0.6362902494331066\n",
            "97th percentile of duration is  0.6574408163265306\n",
            "98th percentile of duration is  0.681934693877551\n",
            "99th percentile of duration is  0.7654394557823128\n",
            "100th percentile of duration is  2.282766439909297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbMb4Y0RaNoA"
      },
      "source": [
        "<font size=4>Grader function 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMoyLLSAaNoF",
        "outputId": "d547cf31-4da3-45d1-821a-4cf0eda4457e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def grader_processed():\n",
        "    flag_columns = (all(X_train_processed.columns==['raw_data', 'duration'])) and (all(X_test_processed.columns==['raw_data', 'duration']))\n",
        "    flag_shape = (X_train_processed.shape ==(1400, 2)) and (X_test_processed.shape==(600,2))\n",
        "    return flag_columns and flag_shape\n",
        "grader_processed()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cux3_jfcaNoM"
      },
      "source": [
        "<b>Based on our analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec. It is similar to pad_sequence for a text dataset.</b>\n",
        "\n",
        "<b>While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 0.8*22050 = 17640\n",
        "</b>\n",
        "<b>Pad with Zero if length of sequence is less than 17640 else Truncate the number. </b>\n",
        "\n",
        "<b> Also create a masking vector for train and test. </b>\n",
        "\n",
        "<b> masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type must be bool.</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voqSEyvcaNoO"
      },
      "source": [
        "max_length  = 17640"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1-_r20BaNoW"
      },
      "source": [
        "## as discussed above, Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
        "## save in the X_train_pad_seq, X_test_pad_seq\n",
        "## also Create masking vector X_train_mask, X_test_mask\n",
        "\n",
        "## all the X_train_pad_seq, X_test_pad_seq, X_train_mask, X_test_mask will be numpy arrays mask vector dtype must be bool.\n",
        "\n",
        "def mask_pad(data):\n",
        "    from tqdm import tqdm\n",
        "    pad_sequence = np.zeros((len(data),max_length))\n",
        "    mask = np.zeros((len(data),max_length))\n",
        "    for n,val in tqdm(enumerate((data.values))):\n",
        "        if len(val)<max_length:\n",
        "            #pad\n",
        "            pad_sequence[n] = np.append(val,[0]*(max_length-len(val)))\n",
        "            mask[n] = np.where(pad_sequence[n]==0,0,1)\n",
        "        else:\n",
        "            #truncate \n",
        "            pad_sequence[n] = pad_sequence[n][0:max_length]\n",
        "            mask[n] = np.where(pad_sequence[n]==0,0,1)\n",
        "    return pad_sequence,mask.astype(bool)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad_seq,X_train_mask = mask_pad(X_train_processed[\"raw_data\"])\n",
        "X_test_pad_seq,X_test_mask = mask_pad(X_test_processed[\"raw_data\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRqjpCFqeedv",
        "outputId": "17cc4a4a-4441-4276-d7c2-7730b282dd69"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1400it [00:01, 1120.01it/s]\n",
            "600it [00:00, 1279.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad_seq.shape,X_train_mask.shape,X_test_pad_seq.shape,X_test_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNsa8BCblP-g",
        "outputId": "8dc7b388-ac0a-4f7f-ff73-5be13c15e549"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1400, 17640), (1400, 17640), (600, 17640), (600, 17640))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)"
      ],
      "metadata": {
        "id": "VTAWdnfblUK0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj4pjrUFlYY3",
        "outputId": "8f895c19-d047-4e8f-d7ed-95743d6fc6ec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1400,), (600,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEHMgm4DaNoe"
      },
      "source": [
        "<font size=4>Grader function 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th3KhplGaNof",
        "outputId": "57d45474-c0b7-43ff-aa8d-d75d28b7a1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def grader_padoutput():\n",
        "    flag_padshape = (X_train_pad_seq.shape==(1400, 17640)) and (X_test_pad_seq.shape==(600, 17640)) and (y_train.shape==(1400,))\n",
        "    flag_maskshape = (X_train_mask.shape==(1400, 17640)) and (X_test_mask.shape==(600, 17640)) and (y_test.shape==(600,))\n",
        "    flag_dtype = (X_train_mask.dtype==bool) and (X_test_mask.dtype==bool)\n",
        "    return flag_padshape and flag_maskshape and flag_dtype\n",
        "grader_padoutput()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0kaYQ1jaNop"
      },
      "source": [
        "### 1. Giving Raw data directly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGHxh3jTaNoq"
      },
      "source": [
        "\n",
        "Now we have\n",
        "\n",
        "Train data: X_train_pad_seq, X_train_mask and y_train  \n",
        "Test data: X_test_pad_seq, X_test_mask and y_test   \n",
        "\n",
        "We will create a LSTM model which takes this input. \n",
        "\n",
        "Task:\n",
        "\n",
        "1. Create an LSTM network which takes \"X_train_pad_seq\" as input, \"X_train_mask\" as mask input. You can use any number of LSTM cells. Please read LSTM documentation(https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) in tensorflow to know more about mask and also https://www.tensorflow.org/guide/keras/masking_and_padding \n",
        "2. Get the final output of the LSTM and give it to Dense layer of any size and then give it to Dense layer of size 10(because we have 10 outputs) and then compile with the sparse categorical cross entropy( because we are not converting it to one hot vectors). Also check the datatype of class labels(y_values) and make sure that you convert your class labels  to integer datatype before fitting in the model.\n",
        "3. While defining your model make sure that you pass both the input layer and mask input layer as input to lstm layer as follows\n",
        "<img src='https://i.imgur.com/FvcgvbY.jpg'>\n",
        "4. Use tensorboard to plot the graphs of loss and metric(use custom micro F1 score as metric) and histograms of gradients. You can write your code for computing F1 score using this <a  href='https://i.imgur.com/8YULUcu.jpg'>link</a> \n",
        "\n",
        "5. make sure that it won't overfit. \n",
        "6. You are free to include any regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8yg951AaNor"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "import tensorflow as tf"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8y1sgeVaNoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68d05d0-e5dc-4e77-bbf1-5ebfa7c50962"
      },
      "source": [
        "## as discussed above, please write the architecture of the model.\n",
        "## you will have two input layers in your model (data input layer and mask input layer)\n",
        "## make sure that you have defined the data type of masking layer as bool\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "seq_input_layer = Input(shape=(max_length,1), dtype='float32',name='seq_inp')\n",
        "mask_input_layer = Input(shape=(max_length), dtype='bool',name='mask_inp')\n",
        "lstm1 = LSTM(64)(seq_input_layer,mask=mask_input_layer)\n",
        "fc1 = Dense(64,activation='relu',kernel_initializer='he_uniform')(lstm1)\n",
        "dp1 = Dropout(0.2)(fc1)\n",
        "output_layer = Dense(10,activation='softmax')(dp1)\n",
        "\n",
        "model_1 = Model(inputs=[seq_input_layer,mask_input_layer],outputs=output_layer)\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " seq_inp (InputLayer)           [(None, 17640, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " mask_inp (InputLayer)          [(None, 17640)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 64)           16896       ['seq_inp[0][0]',                \n",
            "                                                                  'mask_inp[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           4160        ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           650         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,706\n",
            "Trainable params: 21,706\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPj_DGW2aNo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15894994-86a1-4139-c188-426f01b0dab1"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def f1s(y_true,y_pred):\n",
        "  y = np.argmax(y_pred,axis=1)\n",
        "  score=f1_score(y_true,y,average='micro')\n",
        "  return score\n",
        "def micro_f1s(y_true,y_pred):\n",
        "    return tf.py_function(f1s,(y_true,y_pred),tf.double)\n",
        "\n",
        "import datetime\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "log_dir = \"log1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "              \n",
        "#model compilation\n",
        "model_1.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',micro_f1s])\n",
        "              \n",
        "#training the model\n",
        "a=model_1.fit([X_train_pad_seq,X_train_mask],y_train,epochs=2,callbacks=[tensorboard_callback],validation_data=([X_test_pad_seq,X_test_mask],y_test))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "44/44 [==============================] - 695s 16s/step - loss: 2.3044 - accuracy: 0.0979 - micro_f1s: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000 - val_micro_f1s: 0.0998\n",
            "Epoch 2/2\n",
            "44/44 [==============================] - 717s 16s/step - loss: 2.3034 - accuracy: 0.1021 - micro_f1s: 0.1018 - val_loss: 2.3026 - val_accuracy: 0.1017 - val_micro_f1s: 0.1020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fwk0X4zaNpR"
      },
      "source": [
        "### 2. Converting into spectrogram and giving spectrogram data as input  \n",
        "\n",
        "We can use librosa to convert raw data into spectrogram. A spectrogram shows the features in a two-dimensional representation with the\n",
        "intensity of a frequency at a point in time i.e we are converting Time domain to frequency domain. you can read more about this in https://pnsn.org/spectrograms/what-is-a-spectrogram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb5AGzTjaNpS"
      },
      "source": [
        "def convert_to_spectrogram(raw_data):\n",
        "    '''converting to spectrogram'''\n",
        "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
        "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
        "    return logmel_spectrum"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B__rN4RjaNpc"
      },
      "source": [
        "##use convert_to_spectrogram and convert every raw sequence in X_train_pad_seq and X_test_pad-seq.\n",
        "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n",
        "X_train_spectrogram = np.array([convert_to_spectrogram(x) for x in X_train_pad_seq])\n",
        "X_test_spectrogram = np.array([convert_to_spectrogram(x) for x in X_test_pad_seq])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_spectrogram.shape,X_test_spectrogram.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03AU8VUBmRCB",
        "outputId": "19ad05b5-a5b6-4448-f4d6-eee0b8048601"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1400, 64, 35), (600, 64, 35))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr1ynYZnaNpj"
      },
      "source": [
        "<font size=4>Grader function 6 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oniXBXcsaNpk",
        "outputId": "0ed01e37-a2d3-4b78-ac0d-1d9c4ce72deb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def grader_spectrogram():\n",
        "    flag_shape = (X_train_spectrogram.shape==(1400,64, 35)) and (X_test_spectrogram.shape == (600, 64, 35))\n",
        "    return flag_shape\n",
        "grader_spectrogram()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxlEVyIYaNpt"
      },
      "source": [
        "\n",
        "Now we have\n",
        "\n",
        "Train data: X_train_spectrogram and y_train  \n",
        "Test data: X_test_spectrogram and y_test   \n",
        "\n",
        "We will create a LSTM model which takes this input. \n",
        "\n",
        "Task:\n",
        "\n",
        "1. Create an LSTM network which takes \"X_train_spectrogram\" as input and has to return output at every time step. \n",
        "2. Average the output of every time step and give this to the Dense layer of any size. \n",
        "(ex: Output from LSTM will be  (None, time_steps, features) average the output of every time step i.e, you should get (None,time_steps) \n",
        "and then pass to dense layer )\n",
        "3. give the above output to Dense layer of size 10( output layer) and train the network with sparse categorical cross entropy.  \n",
        "4. Use tensorboard to plot the graphs of loss and metric(use custom micro F1 score as metric) and histograms of gradients. You can write your code for computing F1 score using this <a  href='https://i.imgur.com/8YULUcu.jpg'>link</a> \n",
        "5. make sure that it won't overfit. \n",
        "6. You are free to include any regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, TimeDistributed,GlobalAveragePooling2D,GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "zNYRnJyCmbte"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaQjaiiGaNpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82388ca-1342-4968-99a5-90e383e92e51"
      },
      "source": [
        "# write the architecture of the model\n",
        "#print model.summary and make sure that it is following point 2 mentioned above\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "seq_input_layer = Input(shape=(64,35), dtype='float32',name='seq_inp')\n",
        "#mask_inp_layer = Input(shape=(max_length), dtype='bool',name='mask_inp')\n",
        "lstm = LSTM(64,input_shape=(64,35),return_sequences=True)(seq_input_layer)\n",
        "gap = GlobalAveragePooling1D()(lstm)\n",
        "fc1 = Dense(64,activation='relu',kernel_initializer='he_uniform')(gap)\n",
        "dp1 = Dropout(0.2)(fc1)\n",
        "output_layer = Dense(10,activation='softmax')(dp1)\n",
        "\n",
        "model_2 = Model(inputs=seq_input_layer,outputs=output_layer)\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " seq_inp (InputLayer)        [(None, 64, 35)]          0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64, 64)            25600     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,410\n",
            "Trainable params: 30,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "862fP2e-aNp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3ec9ac-4bb1-4016-ad1f-765d5e641f3a"
      },
      "source": [
        "#compile and fit your model.\n",
        "#model2.fit([X_train_spectrogram],y_train_int,......)\n",
        "\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "import datetime\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def f1s(y_true,y_pred):\n",
        "  y = np.argmax(y_pred,axis=1)\n",
        "  score=f1_score(y_true,y,average='micro')\n",
        "  return score\n",
        "\n",
        "#auc metric\n",
        "def micro_f1s(y_true,y_pred):\n",
        "    return tf.py_function(f1s,(y_true,y_pred),tf.double)\n",
        "\n",
        "#tensorboard\n",
        "log_dir = \"log1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#optimizer defining \n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "              \n",
        "#model compilation\n",
        "model_2.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',micro_f1s])\n",
        "              \n",
        "#training the model\n",
        "model_2.fit(X_train_spectrogram,y_train,epochs=100,callbacks=[tensorboard_callback],validation_data=(X_test_spectrogram,y_test))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "44/44 [==============================] - 5s 67ms/step - loss: 2.3423 - accuracy: 0.1214 - micro_f1s: 0.1210 - val_loss: 2.2005 - val_accuracy: 0.2117 - val_micro_f1s: 0.2122\n",
            "Epoch 2/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 2.1804 - accuracy: 0.1886 - micro_f1s: 0.1887 - val_loss: 2.0946 - val_accuracy: 0.2450 - val_micro_f1s: 0.2445\n",
            "Epoch 3/100\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 2.0662 - accuracy: 0.2629 - micro_f1s: 0.2630 - val_loss: 1.9795 - val_accuracy: 0.3183 - val_micro_f1s: 0.3180\n",
            "Epoch 4/100\n",
            "44/44 [==============================] - 3s 70ms/step - loss: 1.9543 - accuracy: 0.3086 - micro_f1s: 0.3080 - val_loss: 1.8819 - val_accuracy: 0.3367 - val_micro_f1s: 0.3372\n",
            "Epoch 5/100\n",
            "44/44 [==============================] - 2s 44ms/step - loss: 1.8769 - accuracy: 0.3336 - micro_f1s: 0.3336 - val_loss: 1.7568 - val_accuracy: 0.3833 - val_micro_f1s: 0.3843\n",
            "Epoch 6/100\n",
            "44/44 [==============================] - 2s 44ms/step - loss: 1.8095 - accuracy: 0.3721 - micro_f1s: 0.3717 - val_loss: 1.6887 - val_accuracy: 0.4283 - val_micro_f1s: 0.4282\n",
            "Epoch 7/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 1.7204 - accuracy: 0.3829 - micro_f1s: 0.3833 - val_loss: 1.5992 - val_accuracy: 0.4783 - val_micro_f1s: 0.4792\n",
            "Epoch 8/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 1.6725 - accuracy: 0.4050 - micro_f1s: 0.4048 - val_loss: 1.5725 - val_accuracy: 0.4867 - val_micro_f1s: 0.4863\n",
            "Epoch 9/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 1.6474 - accuracy: 0.4179 - micro_f1s: 0.4169 - val_loss: 1.5311 - val_accuracy: 0.4683 - val_micro_f1s: 0.4688\n",
            "Epoch 10/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 1.5903 - accuracy: 0.4414 - micro_f1s: 0.4418 - val_loss: 1.5150 - val_accuracy: 0.4933 - val_micro_f1s: 0.4940\n",
            "Epoch 11/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 1.5257 - accuracy: 0.4536 - micro_f1s: 0.4524 - val_loss: 1.4469 - val_accuracy: 0.4983 - val_micro_f1s: 0.4978\n",
            "Epoch 12/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 1.5200 - accuracy: 0.4479 - micro_f1s: 0.4467 - val_loss: 1.4542 - val_accuracy: 0.4983 - val_micro_f1s: 0.4989\n",
            "Epoch 13/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 1.4719 - accuracy: 0.4800 - micro_f1s: 0.4789 - val_loss: 1.3704 - val_accuracy: 0.5667 - val_micro_f1s: 0.5669\n",
            "Epoch 14/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 1.4155 - accuracy: 0.5329 - micro_f1s: 0.5329 - val_loss: 1.3726 - val_accuracy: 0.5267 - val_micro_f1s: 0.5263\n",
            "Epoch 15/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 1.4049 - accuracy: 0.5150 - micro_f1s: 0.5149 - val_loss: 1.3311 - val_accuracy: 0.5500 - val_micro_f1s: 0.5499\n",
            "Epoch 16/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 1.3817 - accuracy: 0.5071 - micro_f1s: 0.5066 - val_loss: 1.3500 - val_accuracy: 0.5600 - val_micro_f1s: 0.5587\n",
            "Epoch 17/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 1.3888 - accuracy: 0.5043 - micro_f1s: 0.5043 - val_loss: 1.3079 - val_accuracy: 0.5817 - val_micro_f1s: 0.5828\n",
            "Epoch 18/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 1.3454 - accuracy: 0.5236 - micro_f1s: 0.5234 - val_loss: 1.2491 - val_accuracy: 0.6017 - val_micro_f1s: 0.6009\n",
            "Epoch 19/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 1.3028 - accuracy: 0.5514 - micro_f1s: 0.5511 - val_loss: 1.2492 - val_accuracy: 0.6150 - val_micro_f1s: 0.6146\n",
            "Epoch 20/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 1.2925 - accuracy: 0.5586 - micro_f1s: 0.5582 - val_loss: 1.2184 - val_accuracy: 0.5800 - val_micro_f1s: 0.5795\n",
            "Epoch 21/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 1.2662 - accuracy: 0.5600 - micro_f1s: 0.5601 - val_loss: 1.1555 - val_accuracy: 0.6500 - val_micro_f1s: 0.6497\n",
            "Epoch 22/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 1.2553 - accuracy: 0.5664 - micro_f1s: 0.5668 - val_loss: 1.1681 - val_accuracy: 0.6433 - val_micro_f1s: 0.6431\n",
            "Epoch 23/100\n",
            "44/44 [==============================] - 2s 51ms/step - loss: 1.2014 - accuracy: 0.5921 - micro_f1s: 0.5921 - val_loss: 1.1026 - val_accuracy: 0.6317 - val_micro_f1s: 0.6321\n",
            "Epoch 24/100\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 1.1842 - accuracy: 0.5979 - micro_f1s: 0.5968 - val_loss: 1.1047 - val_accuracy: 0.6417 - val_micro_f1s: 0.6420\n",
            "Epoch 25/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 1.1525 - accuracy: 0.6186 - micro_f1s: 0.6186 - val_loss: 1.0795 - val_accuracy: 0.6383 - val_micro_f1s: 0.6382\n",
            "Epoch 26/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 1.1496 - accuracy: 0.6029 - micro_f1s: 0.6023 - val_loss: 1.1086 - val_accuracy: 0.6283 - val_micro_f1s: 0.6288\n",
            "Epoch 27/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 1.1522 - accuracy: 0.6121 - micro_f1s: 0.6125 - val_loss: 1.1137 - val_accuracy: 0.6250 - val_micro_f1s: 0.6245\n",
            "Epoch 28/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 1.0869 - accuracy: 0.6371 - micro_f1s: 0.6375 - val_loss: 1.0662 - val_accuracy: 0.6350 - val_micro_f1s: 0.6354\n",
            "Epoch 29/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 1.0778 - accuracy: 0.6400 - micro_f1s: 0.6399 - val_loss: 1.0673 - val_accuracy: 0.6417 - val_micro_f1s: 0.6420\n",
            "Epoch 30/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 1.0494 - accuracy: 0.6636 - micro_f1s: 0.6634 - val_loss: 1.0179 - val_accuracy: 0.6717 - val_micro_f1s: 0.6716\n",
            "Epoch 31/100\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 1.0599 - accuracy: 0.6450 - micro_f1s: 0.6449 - val_loss: 1.0505 - val_accuracy: 0.6750 - val_micro_f1s: 0.6754\n",
            "Epoch 32/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 1.0207 - accuracy: 0.6614 - micro_f1s: 0.6615 - val_loss: 1.0385 - val_accuracy: 0.6433 - val_micro_f1s: 0.6442\n",
            "Epoch 33/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 1.0325 - accuracy: 0.6586 - micro_f1s: 0.6591 - val_loss: 0.9456 - val_accuracy: 0.6783 - val_micro_f1s: 0.6776\n",
            "Epoch 34/100\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 1.0028 - accuracy: 0.6629 - micro_f1s: 0.6622 - val_loss: 0.9653 - val_accuracy: 0.6867 - val_micro_f1s: 0.6875\n",
            "Epoch 35/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 1.0120 - accuracy: 0.6621 - micro_f1s: 0.6615 - val_loss: 0.9591 - val_accuracy: 0.6900 - val_micro_f1s: 0.6897\n",
            "Epoch 36/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.9886 - accuracy: 0.6729 - micro_f1s: 0.6721 - val_loss: 0.9401 - val_accuracy: 0.6900 - val_micro_f1s: 0.6902\n",
            "Epoch 37/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.9664 - accuracy: 0.6864 - micro_f1s: 0.6866 - val_loss: 0.9471 - val_accuracy: 0.6667 - val_micro_f1s: 0.6661\n",
            "Epoch 38/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.9832 - accuracy: 0.6593 - micro_f1s: 0.6591 - val_loss: 0.9023 - val_accuracy: 0.7183 - val_micro_f1s: 0.7198\n",
            "Epoch 39/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.9423 - accuracy: 0.6879 - micro_f1s: 0.6882 - val_loss: 1.0120 - val_accuracy: 0.6700 - val_micro_f1s: 0.6700\n",
            "Epoch 40/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.9293 - accuracy: 0.6871 - micro_f1s: 0.6873 - val_loss: 0.9596 - val_accuracy: 0.6767 - val_micro_f1s: 0.6771\n",
            "Epoch 41/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.9102 - accuracy: 0.7079 - micro_f1s: 0.7088 - val_loss: 0.8746 - val_accuracy: 0.7200 - val_micro_f1s: 0.7204\n",
            "Epoch 42/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.8931 - accuracy: 0.7164 - micro_f1s: 0.7159 - val_loss: 0.9440 - val_accuracy: 0.6600 - val_micro_f1s: 0.6606\n",
            "Epoch 43/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.9075 - accuracy: 0.6907 - micro_f1s: 0.6911 - val_loss: 0.9122 - val_accuracy: 0.6800 - val_micro_f1s: 0.6804\n",
            "Epoch 44/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.8897 - accuracy: 0.6921 - micro_f1s: 0.6920 - val_loss: 0.8558 - val_accuracy: 0.7133 - val_micro_f1s: 0.7138\n",
            "Epoch 45/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.8954 - accuracy: 0.7079 - micro_f1s: 0.7074 - val_loss: 0.8563 - val_accuracy: 0.7400 - val_micro_f1s: 0.7407\n",
            "Epoch 46/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.8556 - accuracy: 0.7150 - micro_f1s: 0.7147 - val_loss: 0.8445 - val_accuracy: 0.7283 - val_micro_f1s: 0.7286\n",
            "Epoch 47/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.8624 - accuracy: 0.7150 - micro_f1s: 0.7154 - val_loss: 0.8387 - val_accuracy: 0.7317 - val_micro_f1s: 0.7325\n",
            "Epoch 48/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.8554 - accuracy: 0.7193 - micro_f1s: 0.7190 - val_loss: 0.8534 - val_accuracy: 0.7117 - val_micro_f1s: 0.7122\n",
            "Epoch 49/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.8360 - accuracy: 0.7207 - micro_f1s: 0.7214 - val_loss: 0.8279 - val_accuracy: 0.7400 - val_micro_f1s: 0.7407\n",
            "Epoch 50/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.8599 - accuracy: 0.7186 - micro_f1s: 0.7188 - val_loss: 0.8724 - val_accuracy: 0.7067 - val_micro_f1s: 0.7056\n",
            "Epoch 51/100\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 0.8412 - accuracy: 0.7193 - micro_f1s: 0.7197 - val_loss: 0.8150 - val_accuracy: 0.7317 - val_micro_f1s: 0.7319\n",
            "Epoch 52/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.8258 - accuracy: 0.7250 - micro_f1s: 0.7256 - val_loss: 0.8266 - val_accuracy: 0.7250 - val_micro_f1s: 0.7248\n",
            "Epoch 53/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.8422 - accuracy: 0.7293 - micro_f1s: 0.7301 - val_loss: 0.8371 - val_accuracy: 0.7233 - val_micro_f1s: 0.7242\n",
            "Epoch 54/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.8021 - accuracy: 0.7393 - micro_f1s: 0.7393 - val_loss: 0.8518 - val_accuracy: 0.7083 - val_micro_f1s: 0.7083\n",
            "Epoch 55/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.8247 - accuracy: 0.7171 - micro_f1s: 0.7173 - val_loss: 0.8095 - val_accuracy: 0.7267 - val_micro_f1s: 0.7275\n",
            "Epoch 56/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.7714 - accuracy: 0.7379 - micro_f1s: 0.7375 - val_loss: 0.7462 - val_accuracy: 0.7717 - val_micro_f1s: 0.7714\n",
            "Epoch 57/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.7402 - accuracy: 0.7479 - micro_f1s: 0.7474 - val_loss: 0.7880 - val_accuracy: 0.7550 - val_micro_f1s: 0.7544\n",
            "Epoch 58/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.7844 - accuracy: 0.7364 - micro_f1s: 0.7360 - val_loss: 0.8256 - val_accuracy: 0.7400 - val_micro_f1s: 0.7401\n",
            "Epoch 59/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.7655 - accuracy: 0.7564 - micro_f1s: 0.7569 - val_loss: 0.7561 - val_accuracy: 0.7650 - val_micro_f1s: 0.7654\n",
            "Epoch 60/100\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 0.7442 - accuracy: 0.7586 - micro_f1s: 0.7580 - val_loss: 0.7478 - val_accuracy: 0.7600 - val_micro_f1s: 0.7615\n",
            "Epoch 61/100\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 0.7719 - accuracy: 0.7443 - micro_f1s: 0.7443 - val_loss: 0.7910 - val_accuracy: 0.7517 - val_micro_f1s: 0.7522\n",
            "Epoch 62/100\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 0.7385 - accuracy: 0.7643 - micro_f1s: 0.7637 - val_loss: 0.7691 - val_accuracy: 0.7483 - val_micro_f1s: 0.7500\n",
            "Epoch 63/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.7677 - accuracy: 0.7379 - micro_f1s: 0.7375 - val_loss: 0.8239 - val_accuracy: 0.7200 - val_micro_f1s: 0.7198\n",
            "Epoch 64/100\n",
            "44/44 [==============================] - 3s 76ms/step - loss: 0.7322 - accuracy: 0.7536 - micro_f1s: 0.7526 - val_loss: 0.7650 - val_accuracy: 0.7533 - val_micro_f1s: 0.7527\n",
            "Epoch 65/100\n",
            "44/44 [==============================] - 3s 61ms/step - loss: 0.7488 - accuracy: 0.7557 - micro_f1s: 0.7562 - val_loss: 0.7993 - val_accuracy: 0.7400 - val_micro_f1s: 0.7396\n",
            "Epoch 66/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.7224 - accuracy: 0.7629 - micro_f1s: 0.7628 - val_loss: 0.7821 - val_accuracy: 0.7450 - val_micro_f1s: 0.7456\n",
            "Epoch 67/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.7075 - accuracy: 0.7614 - micro_f1s: 0.7618 - val_loss: 0.7813 - val_accuracy: 0.7400 - val_micro_f1s: 0.7396\n",
            "Epoch 68/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.7091 - accuracy: 0.7550 - micro_f1s: 0.7554 - val_loss: 0.7590 - val_accuracy: 0.7650 - val_micro_f1s: 0.7659\n",
            "Epoch 69/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.7099 - accuracy: 0.7564 - micro_f1s: 0.7569 - val_loss: 0.7825 - val_accuracy: 0.7467 - val_micro_f1s: 0.7473\n",
            "Epoch 70/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.6831 - accuracy: 0.7736 - micro_f1s: 0.7725 - val_loss: 0.7134 - val_accuracy: 0.7617 - val_micro_f1s: 0.7621\n",
            "Epoch 71/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.6848 - accuracy: 0.7664 - micro_f1s: 0.7656 - val_loss: 0.7227 - val_accuracy: 0.7817 - val_micro_f1s: 0.7818\n",
            "Epoch 72/100\n",
            "44/44 [==============================] - 2s 45ms/step - loss: 0.6784 - accuracy: 0.7586 - micro_f1s: 0.7585 - val_loss: 0.7238 - val_accuracy: 0.7800 - val_micro_f1s: 0.7812\n",
            "Epoch 73/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 0.6664 - accuracy: 0.7771 - micro_f1s: 0.7768 - val_loss: 0.7531 - val_accuracy: 0.7583 - val_micro_f1s: 0.7582\n",
            "Epoch 74/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6999 - accuracy: 0.7607 - micro_f1s: 0.7604 - val_loss: 0.7637 - val_accuracy: 0.7467 - val_micro_f1s: 0.7473\n",
            "Epoch 75/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.6710 - accuracy: 0.7607 - micro_f1s: 0.7604 - val_loss: 0.7334 - val_accuracy: 0.7617 - val_micro_f1s: 0.7621\n",
            "Epoch 76/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.6603 - accuracy: 0.7721 - micro_f1s: 0.7718 - val_loss: 0.7269 - val_accuracy: 0.7650 - val_micro_f1s: 0.7659\n",
            "Epoch 77/100\n",
            "44/44 [==============================] - 2s 47ms/step - loss: 0.6979 - accuracy: 0.7650 - micro_f1s: 0.7656 - val_loss: 0.7358 - val_accuracy: 0.7450 - val_micro_f1s: 0.7451\n",
            "Epoch 78/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.6604 - accuracy: 0.7736 - micro_f1s: 0.7730 - val_loss: 0.7031 - val_accuracy: 0.7717 - val_micro_f1s: 0.7725\n",
            "Epoch 79/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6643 - accuracy: 0.7771 - micro_f1s: 0.7772 - val_loss: 0.7064 - val_accuracy: 0.7783 - val_micro_f1s: 0.7785\n",
            "Epoch 80/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.6798 - accuracy: 0.7771 - micro_f1s: 0.7775 - val_loss: 0.7486 - val_accuracy: 0.7567 - val_micro_f1s: 0.7566\n",
            "Epoch 81/100\n",
            "44/44 [==============================] - 2s 51ms/step - loss: 0.6496 - accuracy: 0.7850 - micro_f1s: 0.7848 - val_loss: 0.7183 - val_accuracy: 0.7800 - val_micro_f1s: 0.7812\n",
            "Epoch 82/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.6552 - accuracy: 0.7871 - micro_f1s: 0.7874 - val_loss: 0.6814 - val_accuracy: 0.7783 - val_micro_f1s: 0.7780\n",
            "Epoch 83/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6268 - accuracy: 0.7921 - micro_f1s: 0.7921 - val_loss: 0.7464 - val_accuracy: 0.7517 - val_micro_f1s: 0.7527\n",
            "Epoch 84/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6714 - accuracy: 0.7671 - micro_f1s: 0.7678 - val_loss: 0.7115 - val_accuracy: 0.7733 - val_micro_f1s: 0.7741\n",
            "Epoch 85/100\n",
            "44/44 [==============================] - 2s 48ms/step - loss: 0.6603 - accuracy: 0.7800 - micro_f1s: 0.7791 - val_loss: 0.7057 - val_accuracy: 0.7567 - val_micro_f1s: 0.7566\n",
            "Epoch 86/100\n",
            "44/44 [==============================] - 2s 51ms/step - loss: 0.6256 - accuracy: 0.7879 - micro_f1s: 0.7881 - val_loss: 0.7103 - val_accuracy: 0.7717 - val_micro_f1s: 0.7714\n",
            "Epoch 87/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6206 - accuracy: 0.7907 - micro_f1s: 0.7914 - val_loss: 0.6939 - val_accuracy: 0.7783 - val_micro_f1s: 0.7796\n",
            "Epoch 88/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6462 - accuracy: 0.7814 - micro_f1s: 0.7812 - val_loss: 0.7041 - val_accuracy: 0.7683 - val_micro_f1s: 0.7686\n",
            "Epoch 89/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6051 - accuracy: 0.7943 - micro_f1s: 0.7945 - val_loss: 0.7328 - val_accuracy: 0.7600 - val_micro_f1s: 0.7599\n",
            "Epoch 90/100\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 0.6458 - accuracy: 0.7800 - micro_f1s: 0.7794 - val_loss: 0.7423 - val_accuracy: 0.7700 - val_micro_f1s: 0.7703\n",
            "Epoch 91/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.5980 - accuracy: 0.7893 - micro_f1s: 0.7898 - val_loss: 0.6766 - val_accuracy: 0.7900 - val_micro_f1s: 0.7911\n",
            "Epoch 92/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.6157 - accuracy: 0.7957 - micro_f1s: 0.7959 - val_loss: 0.7305 - val_accuracy: 0.7550 - val_micro_f1s: 0.7560\n",
            "Epoch 93/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6167 - accuracy: 0.7893 - micro_f1s: 0.7898 - val_loss: 0.7386 - val_accuracy: 0.7600 - val_micro_f1s: 0.7604\n",
            "Epoch 94/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.6016 - accuracy: 0.7971 - micro_f1s: 0.7973 - val_loss: 0.6791 - val_accuracy: 0.7933 - val_micro_f1s: 0.7944\n",
            "Epoch 95/100\n",
            "44/44 [==============================] - 2s 49ms/step - loss: 0.5816 - accuracy: 0.8007 - micro_f1s: 0.8011 - val_loss: 0.6872 - val_accuracy: 0.7867 - val_micro_f1s: 0.7873\n",
            "Epoch 96/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.6118 - accuracy: 0.7864 - micro_f1s: 0.7865 - val_loss: 0.6993 - val_accuracy: 0.7733 - val_micro_f1s: 0.7741\n",
            "Epoch 97/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.5984 - accuracy: 0.7879 - micro_f1s: 0.7876 - val_loss: 0.6764 - val_accuracy: 0.7967 - val_micro_f1s: 0.7977\n",
            "Epoch 98/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.5785 - accuracy: 0.7986 - micro_f1s: 0.7990 - val_loss: 0.6803 - val_accuracy: 0.7700 - val_micro_f1s: 0.7714\n",
            "Epoch 99/100\n",
            "44/44 [==============================] - 2s 46ms/step - loss: 0.5785 - accuracy: 0.8057 - micro_f1s: 0.8052 - val_loss: 0.6855 - val_accuracy: 0.7750 - val_micro_f1s: 0.7769\n",
            "Epoch 100/100\n",
            "44/44 [==============================] - 2s 50ms/step - loss: 0.5698 - accuracy: 0.8057 - micro_f1s: 0.8063 - val_loss: 0.6602 - val_accuracy: 0.7883 - val_micro_f1s: 0.7895\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b6b100150>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSl8ZOXjaNqJ"
      },
      "source": [
        "### 3. Data augmentation with raw features \n",
        "\n",
        "Till now we have done with 2000 samples only. It is very less data. We are giving the process of generating augmented data below.\n",
        "\n",
        "There are two types of augmentation:\n",
        "1. time stretching - Time stretching either increases or decreases the length of the file. For time stretching we move the file 30% faster or slower\n",
        "2. pitch shifting - pitch shifting moves the frequencies higher or lower. For pitch shifting we shift up or down one half-step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR4JSEDgaNqK"
      },
      "source": [
        "## generating augmented data. \n",
        "def generate_augmented_data(file_path):\n",
        "    augmented_data = []\n",
        "    samples = load_wav(file_path,get_duration=False)\n",
        "    for time_value in [0.7, 1, 1.3]:\n",
        "        for pitch_value in [-1, 0, 1]:\n",
        "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
        "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
        "            augmented_data.append(final_data)\n",
        "    return augmented_data"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdefb-SaNqS"
      },
      "source": [
        "temp_path = df_audio.iloc[0].path\n",
        "aug_temp = generate_augmented_data(temp_path)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzdG3iS-aNqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37b3949-1f39-4fee-a661-bae8578bdd3e"
      },
      "source": [
        "len(aug_temp)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZckytZsraNqk"
      },
      "source": [
        "## Follow the steps \n",
        "\n",
        "1. Split data 'df_audio' into train and test (80-20 split)\n",
        "\n",
        "2. We have 2000 data points(1600 train points, 400 test points) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFo5SnTLO_sD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test=train_test_split(df_audio['path'],df_audio['label'],random_state=45,test_size=0.2,stratify=df_audio['label'])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdKXVRlpaNql"
      },
      "source": [
        "3. Do augmentation only on X_train,pass each point of X_train to generate_augmented_data function.After augmentation we will get 14400 train points. Make sure that you are augmenting the corresponding class labels (y_train) also.\n",
        "4. Preprocess your X_test using load_wav function.\n",
        "5. Convert the augmented_train_data and test_data to numpy arrays.\n",
        "6. Perform padding and masking on augmented_train_data and test_data.\n",
        "7. After padding define the model similar to model 1 and fit the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8Yh72uYO_sD"
      },
      "source": [
        "<font color='red'> Note </font> - While fitting your model on the augmented data for model 3 you might face Resource exhaust error. One simple hack to avoid that is save the augmented_train_data,augment_y_train,test_data and y_test to Drive or into your local system. Then restart the runtime so that now you can train your model with full RAM capacity. Upload these files again in the new runtime session perform padding and masking and then fit your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBwzbjOzO_sD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b8eb22-2186-423f-e8fe-3c0f01f5e02c"
      },
      "source": [
        "aug1 = []\n",
        "y_aug1 = []\n",
        "for x,y in zip(X_train,y_train):\n",
        "  aug1.extend(generate_augmented_data(x))\n",
        "  y_aug1.extend([y]*9)\n",
        "np.array(aug1).shape,np.array(y_aug1).shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14400,), (14400,))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41vU8M1gO_sD"
      },
      "source": [
        "aug_train = np.array(aug1)\n",
        "ytr_aug = np.array(y_aug1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytr_aug = ytr_aug.astype('int')\n",
        "y_test = y_test.astype('int')"
      ],
      "metadata": {
        "id": "1rQVNG0WuqM-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xte_pp = [load_wav(x)[0] for x in X_test]"
      ],
      "metadata": {
        "id": "VHvgnH8BuwDS"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 17640\n",
        "\n",
        "def mask_pading(data):\n",
        "    from tqdm import tqdm\n",
        "    pad_sequence = np.zeros((len(data),max_length))\n",
        "    mask = np.zeros((len(data),max_length))\n",
        "    for n,val in tqdm(enumerate((data))):\n",
        "        if len(val)<max_length:\n",
        "            #pad\n",
        "            pad_sequence[n] = np.append(val,[0]*(max_length-len(val)))\n",
        "            mask[n] = np.where(pad_sequence[n]==0,0,1)\n",
        "        else:\n",
        "            #truncate \n",
        "            pad_sequence[n] = pad_sequence[n][0:max_length]\n",
        "            mask[n] = np.where(pad_sequence[n]==0,0,1)\n",
        "    return pad_sequence,mask.astype(bool)"
      ],
      "metadata": {
        "id": "XRC_ixxPuwbY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad_seq,X_train_mask = mask_pading(aug_train)\n",
        "X_test_pad_seq,X_test_mask = mask_pading(xte_pp)\n",
        "X_train_pad_seq.shape,X_test_pad_seq.shape,X_train_mask.shape,X_test_mask.shape"
      ],
      "metadata": {
        "id": "mBiTM_EDvOTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f579cd-9cea-4cec-d862-7758075fd5f0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14400it [00:15, 958.44it/s] \n",
            "400it [00:00, 1171.85it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14400, 17640), (400, 17640), (14400, 17640), (400, 17640))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "seq_input_layer = Input(shape=(max_length,1), dtype='float32',name='seq_inp')\n",
        "mask_input_layer = Input(shape=(max_length), dtype='bool',name='mask_inp')\n",
        "lstm = LSTM(64)(seq_input_layer,mask=mask_input_layer)\n",
        "fc1 = Dense(64,activation='relu',kernel_initializer='he_uniform')(lstm)\n",
        "dp1 = Dropout(0.2)(fc1)\n",
        "output_layer = Dense(10,activation='softmax')(dp1)\n",
        "\n",
        "model_3 = Model(inputs=[seq_input_layer,mask_input_layer],outputs=output_layer)\n",
        "\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "q2pjB34FvrtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfaed518-d27a-4fbe-eb5b-cf879ac1d3ee"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " seq_inp (InputLayer)           [(None, 17640, 1)]   0           []                               \n",
            "                                                                                                  \n",
            " mask_inp (InputLayer)          [(None, 17640)]      0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 64)           16896       ['seq_inp[0][0]',                \n",
            "                                                                  'mask_inp[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           4160        ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           650         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,706\n",
            "Trainable params: 21,706\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f1s(y_true,y_pred):\n",
        "  y = np.argmax(y_pred,axis=1)\n",
        "  score=f1_score(y_true,y,average='micro')\n",
        "  return score\n",
        "\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "import datetime\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#auc metric\n",
        "def micro_f1s(y_true,y_pred):\n",
        "    return tf.py_function(f1s,(y_true,y_pred),tf.double)\n",
        "\n",
        "#tensorboard\n",
        "log_dir = \"log1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#optimizer defining \n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "              \n",
        "#model compilation\n",
        "model_3.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',micro_f1s])\n",
        "              \n",
        "#training the model\n",
        "model_3.fit([X_train_pad_seq,X_train_mask],ytr_aug,epochs=2,callbacks=[tensorboard_callback],validation_data=([X_test_pad_seq,X_test_mask],y_test))"
      ],
      "metadata": {
        "id": "CBsWOAx20A0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4a5edb-f053-4cfd-ebfa-1838b02f9a9d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "450/450 [==============================] - 5633s 13s/step - loss: 2.3030 - accuracy: 0.0975 - micro_f1s: 0.0975 - val_loss: 2.3023 - val_accuracy: 0.1050 - val_micro_f1s: 0.1010\n",
            "Epoch 2/2\n",
            "450/450 [==============================] - 5636s 13s/step - loss: 2.3011 - accuracy: 0.1065 - micro_f1s: 0.1065 - val_loss: 2.3022 - val_accuracy: 0.1050 - val_micro_f1s: 0.1034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b6d9aa2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXY9uP7cO_sE"
      },
      "source": [
        "### 4. Data augmentation with spectogram data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EShBfiERO_sE"
      },
      "source": [
        "1. use convert_to_spectrogram and convert the padded data from train and test data to spectogram data.\n",
        "2. The shape of train data will be 14400 x 64 x 35 and shape of test_data will be 400 x 64 x35\n",
        "3. Define the model similar to model 2 and fit the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpVMCEW3O_sE"
      },
      "source": [
        "import numpy as np\n",
        "X_train_spectrogram = np.array([convert_to_spectrogram(x) for x in X_train_pad_seq])\n",
        "X_test_spectrogram = np.array([convert_to_spectrogram(x) for x in X_test_pad_seq])\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40RMwgJ6O_sE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8250b310-83bc-4213-8a2c-aae30acf07aa"
      },
      "source": [
        "X_train_spectrogram.shape,X_test_spectrogram.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14400, 64, 35), (400, 64, 35))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, TimeDistributed,GlobalAveragePooling2D,GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "seq_input_layer = Input(shape=(64,35), dtype='float32',name='seq_inp')\n",
        "#mask_inp_layer = Input(shape=(max_length), dtype='bool',name='mask_inp')\n",
        "lstm = LSTM(64,input_shape=(64,35),return_sequences=True)(seq_input_layer)\n",
        "gap = GlobalAveragePooling1D()(lstm)\n",
        "fc1 = Dense(64,activation='relu',kernel_initializer='he_uniform')(gap)\n",
        "dp1 = Dropout(0.2)(fc1)\n",
        "output_layer = Dense(10,activation='softmax')(dp1)\n",
        "\n",
        "model_4 = Model(inputs=seq_input_layer,outputs=output_layer)\n",
        "\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "SM9QE9W70Rsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f90016-446b-42ef-b47f-50c086fbb297"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " seq_inp (InputLayer)        [(None, 64, 35)]          0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64, 64)            25600     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,410\n",
            "Trainable params: 30,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, make_scorer\n",
        "import datetime\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def f1s(y_true,y_pred):\n",
        "  y = np.argmax(y_pred,axis=1)\n",
        "  score=f1_score(y_true,y,average='micro')\n",
        "  return score\n",
        "\n",
        "#auc metric\n",
        "def micro_f1s(y_true,y_pred):\n",
        "    return tf.py_function(f1s,(y_true,y_pred),tf.double)\n",
        "\n",
        "#tensorboard\n",
        "log_dir = \"log1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#optimizer defining \n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "              \n",
        "#model compilation\n",
        "model_4.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',micro_f1s])\n",
        "              \n",
        "#training the model\n",
        "model_4.fit(X_train_spectrogram,ytr_aug,epochs=150,callbacks=[tensorboard_callback],validation_data=(X_test_spectrogram,y_test))"
      ],
      "metadata": {
        "id": "kdtBBJC-0SAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14033d1f-0b8f-4c48-a3bc-5483c715c83b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "450/450 [==============================] - 18s 35ms/step - loss: 2.0643 - accuracy: 0.2348 - micro_f1s: 0.2348 - val_loss: 1.6960 - val_accuracy: 0.4475 - val_micro_f1s: 0.4375\n",
            "Epoch 2/150\n",
            "450/450 [==============================] - 17s 39ms/step - loss: 1.6958 - accuracy: 0.3881 - micro_f1s: 0.3881 - val_loss: 1.4344 - val_accuracy: 0.5150 - val_micro_f1s: 0.5192\n",
            "Epoch 3/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 1.4967 - accuracy: 0.4680 - micro_f1s: 0.4680 - val_loss: 1.3229 - val_accuracy: 0.5575 - val_micro_f1s: 0.5577\n",
            "Epoch 4/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 1.3743 - accuracy: 0.5139 - micro_f1s: 0.5139 - val_loss: 1.0891 - val_accuracy: 0.6175 - val_micro_f1s: 0.6178\n",
            "Epoch 5/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 1.2885 - accuracy: 0.5428 - micro_f1s: 0.5428 - val_loss: 1.0600 - val_accuracy: 0.6275 - val_micro_f1s: 0.6274\n",
            "Epoch 6/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 1.2023 - accuracy: 0.5716 - micro_f1s: 0.5716 - val_loss: 0.9976 - val_accuracy: 0.6550 - val_micro_f1s: 0.6562\n",
            "Epoch 7/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 1.1221 - accuracy: 0.6068 - micro_f1s: 0.6068 - val_loss: 1.0252 - val_accuracy: 0.6125 - val_micro_f1s: 0.6130\n",
            "Epoch 8/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 1.0763 - accuracy: 0.6190 - micro_f1s: 0.6190 - val_loss: 0.9248 - val_accuracy: 0.6600 - val_micro_f1s: 0.6587\n",
            "Epoch 9/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 1.0296 - accuracy: 0.6386 - micro_f1s: 0.6386 - val_loss: 0.8072 - val_accuracy: 0.7350 - val_micro_f1s: 0.7356\n",
            "Epoch 10/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 1.0054 - accuracy: 0.6467 - micro_f1s: 0.6467 - val_loss: 0.8532 - val_accuracy: 0.7150 - val_micro_f1s: 0.7139\n",
            "Epoch 11/150\n",
            "450/450 [==============================] - 17s 39ms/step - loss: 0.9697 - accuracy: 0.6634 - micro_f1s: 0.6634 - val_loss: 0.8375 - val_accuracy: 0.7025 - val_micro_f1s: 0.7019\n",
            "Epoch 12/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.9512 - accuracy: 0.6676 - micro_f1s: 0.6676 - val_loss: 0.8952 - val_accuracy: 0.6700 - val_micro_f1s: 0.6731\n",
            "Epoch 13/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.9243 - accuracy: 0.6767 - micro_f1s: 0.6767 - val_loss: 0.8019 - val_accuracy: 0.7100 - val_micro_f1s: 0.7115\n",
            "Epoch 14/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.9011 - accuracy: 0.6822 - micro_f1s: 0.6822 - val_loss: 0.7375 - val_accuracy: 0.7450 - val_micro_f1s: 0.7428\n",
            "Epoch 15/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.8965 - accuracy: 0.6866 - micro_f1s: 0.6866 - val_loss: 0.7848 - val_accuracy: 0.6950 - val_micro_f1s: 0.6971\n",
            "Epoch 16/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.8734 - accuracy: 0.6944 - micro_f1s: 0.6944 - val_loss: 0.7690 - val_accuracy: 0.7300 - val_micro_f1s: 0.7332\n",
            "Epoch 17/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.8606 - accuracy: 0.7006 - micro_f1s: 0.7006 - val_loss: 0.6903 - val_accuracy: 0.7625 - val_micro_f1s: 0.7620\n",
            "Epoch 18/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.8261 - accuracy: 0.7094 - micro_f1s: 0.7094 - val_loss: 0.7168 - val_accuracy: 0.7350 - val_micro_f1s: 0.7356\n",
            "Epoch 19/150\n",
            "450/450 [==============================] - 17s 38ms/step - loss: 0.8276 - accuracy: 0.7103 - micro_f1s: 0.7103 - val_loss: 0.7268 - val_accuracy: 0.7300 - val_micro_f1s: 0.7308\n",
            "Epoch 20/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.8123 - accuracy: 0.7140 - micro_f1s: 0.7140 - val_loss: 0.8444 - val_accuracy: 0.6950 - val_micro_f1s: 0.6995\n",
            "Epoch 21/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.7998 - accuracy: 0.7206 - micro_f1s: 0.7206 - val_loss: 0.7088 - val_accuracy: 0.7650 - val_micro_f1s: 0.7668\n",
            "Epoch 22/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.8031 - accuracy: 0.7163 - micro_f1s: 0.7163 - val_loss: 0.6699 - val_accuracy: 0.7650 - val_micro_f1s: 0.7692\n",
            "Epoch 23/150\n",
            "450/450 [==============================] - 16s 34ms/step - loss: 0.7865 - accuracy: 0.7220 - micro_f1s: 0.7220 - val_loss: 0.7062 - val_accuracy: 0.7525 - val_micro_f1s: 0.7548\n",
            "Epoch 24/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.7919 - accuracy: 0.7197 - micro_f1s: 0.7197 - val_loss: 0.6566 - val_accuracy: 0.7725 - val_micro_f1s: 0.7716\n",
            "Epoch 25/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.7659 - accuracy: 0.7299 - micro_f1s: 0.7299 - val_loss: 0.6629 - val_accuracy: 0.7525 - val_micro_f1s: 0.7548\n",
            "Epoch 26/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.7612 - accuracy: 0.7314 - micro_f1s: 0.7314 - val_loss: 0.6837 - val_accuracy: 0.7525 - val_micro_f1s: 0.7524\n",
            "Epoch 27/150\n",
            "450/450 [==============================] - 17s 38ms/step - loss: 0.7704 - accuracy: 0.7254 - micro_f1s: 0.7254 - val_loss: 0.6985 - val_accuracy: 0.7325 - val_micro_f1s: 0.7332\n",
            "Epoch 28/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.7386 - accuracy: 0.7380 - micro_f1s: 0.7380 - val_loss: 0.7505 - val_accuracy: 0.7325 - val_micro_f1s: 0.7356\n",
            "Epoch 29/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.7388 - accuracy: 0.7332 - micro_f1s: 0.7332 - val_loss: 0.6843 - val_accuracy: 0.7450 - val_micro_f1s: 0.7500\n",
            "Epoch 30/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.7298 - accuracy: 0.7415 - micro_f1s: 0.7415 - val_loss: 0.6586 - val_accuracy: 0.7600 - val_micro_f1s: 0.7620\n",
            "Epoch 31/150\n",
            "450/450 [==============================] - 16s 34ms/step - loss: 0.7341 - accuracy: 0.7382 - micro_f1s: 0.7382 - val_loss: 0.6372 - val_accuracy: 0.7650 - val_micro_f1s: 0.7668\n",
            "Epoch 32/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.7227 - accuracy: 0.7442 - micro_f1s: 0.7442 - val_loss: 0.7003 - val_accuracy: 0.7700 - val_micro_f1s: 0.7692\n",
            "Epoch 33/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.7051 - accuracy: 0.7528 - micro_f1s: 0.7528 - val_loss: 0.6431 - val_accuracy: 0.7575 - val_micro_f1s: 0.7572\n",
            "Epoch 34/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.7082 - accuracy: 0.7525 - micro_f1s: 0.7525 - val_loss: 0.6384 - val_accuracy: 0.7675 - val_micro_f1s: 0.7692\n",
            "Epoch 35/150\n",
            "450/450 [==============================] - 18s 39ms/step - loss: 0.7035 - accuracy: 0.7508 - micro_f1s: 0.7508 - val_loss: 0.6844 - val_accuracy: 0.7675 - val_micro_f1s: 0.7692\n",
            "Epoch 36/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.7062 - accuracy: 0.7483 - micro_f1s: 0.7483 - val_loss: 0.6393 - val_accuracy: 0.7700 - val_micro_f1s: 0.7740\n",
            "Epoch 37/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6791 - accuracy: 0.7567 - micro_f1s: 0.7567 - val_loss: 0.6621 - val_accuracy: 0.7475 - val_micro_f1s: 0.7524\n",
            "Epoch 38/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.6824 - accuracy: 0.7605 - micro_f1s: 0.7605 - val_loss: 0.6163 - val_accuracy: 0.7850 - val_micro_f1s: 0.7885\n",
            "Epoch 39/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6724 - accuracy: 0.7605 - micro_f1s: 0.7605 - val_loss: 0.5813 - val_accuracy: 0.7725 - val_micro_f1s: 0.7740\n",
            "Epoch 40/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6571 - accuracy: 0.7681 - micro_f1s: 0.7681 - val_loss: 0.6208 - val_accuracy: 0.7850 - val_micro_f1s: 0.7885\n",
            "Epoch 41/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6845 - accuracy: 0.7593 - micro_f1s: 0.7593 - val_loss: 0.6292 - val_accuracy: 0.7875 - val_micro_f1s: 0.7933\n",
            "Epoch 42/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6757 - accuracy: 0.7603 - micro_f1s: 0.7603 - val_loss: 0.6194 - val_accuracy: 0.7925 - val_micro_f1s: 0.7909\n",
            "Epoch 43/150\n",
            "450/450 [==============================] - 16s 37ms/step - loss: 0.6556 - accuracy: 0.7682 - micro_f1s: 0.7682 - val_loss: 0.6193 - val_accuracy: 0.7800 - val_micro_f1s: 0.7837\n",
            "Epoch 44/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.6469 - accuracy: 0.7728 - micro_f1s: 0.7728 - val_loss: 0.5591 - val_accuracy: 0.8200 - val_micro_f1s: 0.8197\n",
            "Epoch 45/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6526 - accuracy: 0.7689 - micro_f1s: 0.7689 - val_loss: 0.5645 - val_accuracy: 0.8200 - val_micro_f1s: 0.8221\n",
            "Epoch 46/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6467 - accuracy: 0.7715 - micro_f1s: 0.7715 - val_loss: 0.6766 - val_accuracy: 0.7700 - val_micro_f1s: 0.7716\n",
            "Epoch 47/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6435 - accuracy: 0.7721 - micro_f1s: 0.7721 - val_loss: 0.6013 - val_accuracy: 0.7750 - val_micro_f1s: 0.7764\n",
            "Epoch 48/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.6313 - accuracy: 0.7762 - micro_f1s: 0.7762 - val_loss: 0.6425 - val_accuracy: 0.7575 - val_micro_f1s: 0.7596\n",
            "Epoch 49/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6350 - accuracy: 0.7758 - micro_f1s: 0.7758 - val_loss: 0.7054 - val_accuracy: 0.7500 - val_micro_f1s: 0.7548\n",
            "Epoch 50/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6425 - accuracy: 0.7715 - micro_f1s: 0.7715 - val_loss: 0.5958 - val_accuracy: 0.7800 - val_micro_f1s: 0.7812\n",
            "Epoch 51/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.6165 - accuracy: 0.7816 - micro_f1s: 0.7816 - val_loss: 0.6092 - val_accuracy: 0.7775 - val_micro_f1s: 0.7812\n",
            "Epoch 52/150\n",
            "450/450 [==============================] - 18s 40ms/step - loss: 0.6316 - accuracy: 0.7781 - micro_f1s: 0.7781 - val_loss: 0.6390 - val_accuracy: 0.7850 - val_micro_f1s: 0.7885\n",
            "Epoch 53/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6469 - accuracy: 0.7718 - micro_f1s: 0.7718 - val_loss: 0.6310 - val_accuracy: 0.7700 - val_micro_f1s: 0.7740\n",
            "Epoch 54/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6204 - accuracy: 0.7762 - micro_f1s: 0.7762 - val_loss: 0.6327 - val_accuracy: 0.7900 - val_micro_f1s: 0.7957\n",
            "Epoch 55/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6054 - accuracy: 0.7844 - micro_f1s: 0.7844 - val_loss: 0.6944 - val_accuracy: 0.7775 - val_micro_f1s: 0.7837\n",
            "Epoch 56/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.6048 - accuracy: 0.7836 - micro_f1s: 0.7836 - val_loss: 0.5988 - val_accuracy: 0.8050 - val_micro_f1s: 0.8077\n",
            "Epoch 57/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.6264 - accuracy: 0.7758 - micro_f1s: 0.7758 - val_loss: 0.5909 - val_accuracy: 0.8075 - val_micro_f1s: 0.8101\n",
            "Epoch 58/150\n",
            "450/450 [==============================] - 15s 33ms/step - loss: 0.6026 - accuracy: 0.7860 - micro_f1s: 0.7860 - val_loss: 0.5829 - val_accuracy: 0.7975 - val_micro_f1s: 0.7981\n",
            "Epoch 59/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5965 - accuracy: 0.7892 - micro_f1s: 0.7892 - val_loss: 0.6339 - val_accuracy: 0.7800 - val_micro_f1s: 0.7861\n",
            "Epoch 60/150\n",
            "450/450 [==============================] - 18s 39ms/step - loss: 0.6136 - accuracy: 0.7819 - micro_f1s: 0.7819 - val_loss: 0.6262 - val_accuracy: 0.8050 - val_micro_f1s: 0.8077\n",
            "Epoch 61/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5859 - accuracy: 0.7935 - micro_f1s: 0.7935 - val_loss: 0.5656 - val_accuracy: 0.8025 - val_micro_f1s: 0.8053\n",
            "Epoch 62/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5844 - accuracy: 0.7907 - micro_f1s: 0.7907 - val_loss: 0.5871 - val_accuracy: 0.8025 - val_micro_f1s: 0.8077\n",
            "Epoch 63/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5924 - accuracy: 0.7913 - micro_f1s: 0.7913 - val_loss: 0.5679 - val_accuracy: 0.8125 - val_micro_f1s: 0.8125\n",
            "Epoch 64/150\n",
            "450/450 [==============================] - 17s 37ms/step - loss: 0.5820 - accuracy: 0.7943 - micro_f1s: 0.7943 - val_loss: 0.5370 - val_accuracy: 0.8225 - val_micro_f1s: 0.8245\n",
            "Epoch 65/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.5835 - accuracy: 0.7934 - micro_f1s: 0.7934 - val_loss: 0.6410 - val_accuracy: 0.7775 - val_micro_f1s: 0.7812\n",
            "Epoch 66/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5706 - accuracy: 0.7957 - micro_f1s: 0.7957 - val_loss: 0.5858 - val_accuracy: 0.7975 - val_micro_f1s: 0.8005\n",
            "Epoch 67/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5771 - accuracy: 0.7958 - micro_f1s: 0.7958 - val_loss: 0.5284 - val_accuracy: 0.8325 - val_micro_f1s: 0.8365\n",
            "Epoch 68/150\n",
            "450/450 [==============================] - 18s 39ms/step - loss: 0.5801 - accuracy: 0.7931 - micro_f1s: 0.7931 - val_loss: 0.6404 - val_accuracy: 0.8025 - val_micro_f1s: 0.8005\n",
            "Epoch 69/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5767 - accuracy: 0.7960 - micro_f1s: 0.7960 - val_loss: 0.5626 - val_accuracy: 0.8075 - val_micro_f1s: 0.8077\n",
            "Epoch 70/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5889 - accuracy: 0.7910 - micro_f1s: 0.7910 - val_loss: 0.5919 - val_accuracy: 0.8125 - val_micro_f1s: 0.8173\n",
            "Epoch 71/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5632 - accuracy: 0.7997 - micro_f1s: 0.7997 - val_loss: 0.5561 - val_accuracy: 0.8175 - val_micro_f1s: 0.8173\n",
            "Epoch 72/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5687 - accuracy: 0.7946 - micro_f1s: 0.7946 - val_loss: 0.6221 - val_accuracy: 0.7850 - val_micro_f1s: 0.7885\n",
            "Epoch 73/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.5840 - accuracy: 0.7936 - micro_f1s: 0.7936 - val_loss: 0.6079 - val_accuracy: 0.7950 - val_micro_f1s: 0.7957\n",
            "Epoch 74/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5619 - accuracy: 0.8011 - micro_f1s: 0.8011 - val_loss: 0.7347 - val_accuracy: 0.7675 - val_micro_f1s: 0.7716\n",
            "Epoch 75/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5652 - accuracy: 0.7972 - micro_f1s: 0.7972 - val_loss: 0.6399 - val_accuracy: 0.7800 - val_micro_f1s: 0.7861\n",
            "Epoch 76/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5638 - accuracy: 0.8032 - micro_f1s: 0.8032 - val_loss: 0.5397 - val_accuracy: 0.8225 - val_micro_f1s: 0.8245\n",
            "Epoch 77/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5488 - accuracy: 0.8052 - micro_f1s: 0.8052 - val_loss: 0.6229 - val_accuracy: 0.8050 - val_micro_f1s: 0.8101\n",
            "Epoch 78/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5429 - accuracy: 0.8068 - micro_f1s: 0.8068 - val_loss: 0.5982 - val_accuracy: 0.8050 - val_micro_f1s: 0.8029\n",
            "Epoch 79/150\n",
            "450/450 [==============================] - 15s 34ms/step - loss: 0.5464 - accuracy: 0.8079 - micro_f1s: 0.8079 - val_loss: 0.6053 - val_accuracy: 0.8025 - val_micro_f1s: 0.8053\n",
            "Epoch 80/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5597 - accuracy: 0.8026 - micro_f1s: 0.8026 - val_loss: 0.5528 - val_accuracy: 0.8250 - val_micro_f1s: 0.8293\n",
            "Epoch 81/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5371 - accuracy: 0.8069 - micro_f1s: 0.8069 - val_loss: 0.5903 - val_accuracy: 0.7975 - val_micro_f1s: 0.7981\n",
            "Epoch 82/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5600 - accuracy: 0.7997 - micro_f1s: 0.7997 - val_loss: 0.5733 - val_accuracy: 0.8050 - val_micro_f1s: 0.8077\n",
            "Epoch 83/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5267 - accuracy: 0.8134 - micro_f1s: 0.8134 - val_loss: 0.5633 - val_accuracy: 0.8125 - val_micro_f1s: 0.8173\n",
            "Epoch 84/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5481 - accuracy: 0.8042 - micro_f1s: 0.8042 - val_loss: 0.5972 - val_accuracy: 0.8150 - val_micro_f1s: 0.8149\n",
            "Epoch 85/150\n",
            "450/450 [==============================] - 17s 37ms/step - loss: 0.5414 - accuracy: 0.8058 - micro_f1s: 0.8058 - val_loss: 0.5078 - val_accuracy: 0.8425 - val_micro_f1s: 0.8462\n",
            "Epoch 86/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5395 - accuracy: 0.8107 - micro_f1s: 0.8107 - val_loss: 0.5371 - val_accuracy: 0.8175 - val_micro_f1s: 0.8221\n",
            "Epoch 87/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5367 - accuracy: 0.8112 - micro_f1s: 0.8112 - val_loss: 0.5422 - val_accuracy: 0.8225 - val_micro_f1s: 0.8269\n",
            "Epoch 88/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5247 - accuracy: 0.8114 - micro_f1s: 0.8114 - val_loss: 0.5626 - val_accuracy: 0.8175 - val_micro_f1s: 0.8221\n",
            "Epoch 89/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5358 - accuracy: 0.8127 - micro_f1s: 0.8127 - val_loss: 0.5560 - val_accuracy: 0.8125 - val_micro_f1s: 0.8149\n",
            "Epoch 90/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5185 - accuracy: 0.8135 - micro_f1s: 0.8135 - val_loss: 0.5197 - val_accuracy: 0.8275 - val_micro_f1s: 0.8317\n",
            "Epoch 91/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5201 - accuracy: 0.8184 - micro_f1s: 0.8184 - val_loss: 0.5390 - val_accuracy: 0.8025 - val_micro_f1s: 0.8053\n",
            "Epoch 92/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5262 - accuracy: 0.8110 - micro_f1s: 0.8110 - val_loss: 0.6545 - val_accuracy: 0.7775 - val_micro_f1s: 0.7812\n",
            "Epoch 93/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5102 - accuracy: 0.8176 - micro_f1s: 0.8176 - val_loss: 0.6180 - val_accuracy: 0.7850 - val_micro_f1s: 0.7885\n",
            "Epoch 94/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5079 - accuracy: 0.8198 - micro_f1s: 0.8198 - val_loss: 0.5348 - val_accuracy: 0.8275 - val_micro_f1s: 0.8317\n",
            "Epoch 95/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5256 - accuracy: 0.8134 - micro_f1s: 0.8134 - val_loss: 0.5914 - val_accuracy: 0.8100 - val_micro_f1s: 0.8101\n",
            "Epoch 96/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5216 - accuracy: 0.8136 - micro_f1s: 0.8136 - val_loss: 0.5661 - val_accuracy: 0.8325 - val_micro_f1s: 0.8341\n",
            "Epoch 97/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5110 - accuracy: 0.8212 - micro_f1s: 0.8212 - val_loss: 0.5742 - val_accuracy: 0.8175 - val_micro_f1s: 0.8173\n",
            "Epoch 98/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5031 - accuracy: 0.8233 - micro_f1s: 0.8233 - val_loss: 0.5653 - val_accuracy: 0.8125 - val_micro_f1s: 0.8149\n",
            "Epoch 99/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5080 - accuracy: 0.8206 - micro_f1s: 0.8206 - val_loss: 0.5263 - val_accuracy: 0.8300 - val_micro_f1s: 0.8317\n",
            "Epoch 100/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5039 - accuracy: 0.8211 - micro_f1s: 0.8211 - val_loss: 0.5515 - val_accuracy: 0.8375 - val_micro_f1s: 0.8389\n",
            "Epoch 101/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5092 - accuracy: 0.8233 - micro_f1s: 0.8233 - val_loss: 0.5300 - val_accuracy: 0.8350 - val_micro_f1s: 0.8389\n",
            "Epoch 102/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5165 - accuracy: 0.8168 - micro_f1s: 0.8168 - val_loss: 0.5421 - val_accuracy: 0.8150 - val_micro_f1s: 0.8173\n",
            "Epoch 103/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5104 - accuracy: 0.8167 - micro_f1s: 0.8167 - val_loss: 0.5337 - val_accuracy: 0.8325 - val_micro_f1s: 0.8365\n",
            "Epoch 104/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5211 - accuracy: 0.8167 - micro_f1s: 0.8167 - val_loss: 0.5752 - val_accuracy: 0.8100 - val_micro_f1s: 0.8101\n",
            "Epoch 105/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5052 - accuracy: 0.8208 - micro_f1s: 0.8208 - val_loss: 0.6730 - val_accuracy: 0.8000 - val_micro_f1s: 0.8029\n",
            "Epoch 106/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5271 - accuracy: 0.8105 - micro_f1s: 0.8105 - val_loss: 0.5727 - val_accuracy: 0.8050 - val_micro_f1s: 0.8053\n",
            "Epoch 107/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5023 - accuracy: 0.8224 - micro_f1s: 0.8224 - val_loss: 0.5757 - val_accuracy: 0.8250 - val_micro_f1s: 0.8245\n",
            "Epoch 108/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5039 - accuracy: 0.8198 - micro_f1s: 0.8198 - val_loss: 0.6002 - val_accuracy: 0.8125 - val_micro_f1s: 0.8149\n",
            "Epoch 109/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4983 - accuracy: 0.8232 - micro_f1s: 0.8232 - val_loss: 0.5240 - val_accuracy: 0.8325 - val_micro_f1s: 0.8365\n",
            "Epoch 110/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.5029 - accuracy: 0.8179 - micro_f1s: 0.8179 - val_loss: 0.5390 - val_accuracy: 0.8300 - val_micro_f1s: 0.8341\n",
            "Epoch 111/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4964 - accuracy: 0.8215 - micro_f1s: 0.8215 - val_loss: 0.5560 - val_accuracy: 0.8400 - val_micro_f1s: 0.8438\n",
            "Epoch 112/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4807 - accuracy: 0.8253 - micro_f1s: 0.8253 - val_loss: 0.5449 - val_accuracy: 0.8200 - val_micro_f1s: 0.8197\n",
            "Epoch 113/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5005 - accuracy: 0.8231 - micro_f1s: 0.8231 - val_loss: 0.5702 - val_accuracy: 0.8025 - val_micro_f1s: 0.8053\n",
            "Epoch 114/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4903 - accuracy: 0.8267 - micro_f1s: 0.8267 - val_loss: 0.5308 - val_accuracy: 0.8300 - val_micro_f1s: 0.8317\n",
            "Epoch 115/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4943 - accuracy: 0.8237 - micro_f1s: 0.8237 - val_loss: 0.5468 - val_accuracy: 0.8200 - val_micro_f1s: 0.8245\n",
            "Epoch 116/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4762 - accuracy: 0.8285 - micro_f1s: 0.8285 - val_loss: 0.5579 - val_accuracy: 0.8325 - val_micro_f1s: 0.8365\n",
            "Epoch 117/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4918 - accuracy: 0.8235 - micro_f1s: 0.8235 - val_loss: 0.5390 - val_accuracy: 0.8175 - val_micro_f1s: 0.8197\n",
            "Epoch 118/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4867 - accuracy: 0.8256 - micro_f1s: 0.8256 - val_loss: 0.5555 - val_accuracy: 0.8075 - val_micro_f1s: 0.8077\n",
            "Epoch 119/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4870 - accuracy: 0.8269 - micro_f1s: 0.8269 - val_loss: 0.5446 - val_accuracy: 0.8500 - val_micro_f1s: 0.8510\n",
            "Epoch 120/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4925 - accuracy: 0.8271 - micro_f1s: 0.8271 - val_loss: 0.5516 - val_accuracy: 0.8300 - val_micro_f1s: 0.8317\n",
            "Epoch 121/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4836 - accuracy: 0.8244 - micro_f1s: 0.8244 - val_loss: 0.5117 - val_accuracy: 0.8525 - val_micro_f1s: 0.8558\n",
            "Epoch 122/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4855 - accuracy: 0.8277 - micro_f1s: 0.8277 - val_loss: 0.5438 - val_accuracy: 0.8150 - val_micro_f1s: 0.8173\n",
            "Epoch 123/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4835 - accuracy: 0.8250 - micro_f1s: 0.8250 - val_loss: 0.5884 - val_accuracy: 0.8125 - val_micro_f1s: 0.8149\n",
            "Epoch 124/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4885 - accuracy: 0.8242 - micro_f1s: 0.8242 - val_loss: 0.5550 - val_accuracy: 0.8325 - val_micro_f1s: 0.8317\n",
            "Epoch 125/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4834 - accuracy: 0.8265 - micro_f1s: 0.8265 - val_loss: 0.5202 - val_accuracy: 0.8400 - val_micro_f1s: 0.8438\n",
            "Epoch 126/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4758 - accuracy: 0.8322 - micro_f1s: 0.8322 - val_loss: 0.5608 - val_accuracy: 0.8175 - val_micro_f1s: 0.8197\n",
            "Epoch 127/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4575 - accuracy: 0.8362 - micro_f1s: 0.8362 - val_loss: 0.5512 - val_accuracy: 0.8100 - val_micro_f1s: 0.8125\n",
            "Epoch 128/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4865 - accuracy: 0.8249 - micro_f1s: 0.8249 - val_loss: 0.5942 - val_accuracy: 0.7925 - val_micro_f1s: 0.7957\n",
            "Epoch 129/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4716 - accuracy: 0.8326 - micro_f1s: 0.8326 - val_loss: 0.5558 - val_accuracy: 0.8375 - val_micro_f1s: 0.8389\n",
            "Epoch 130/150\n",
            "450/450 [==============================] - 16s 37ms/step - loss: 0.4827 - accuracy: 0.8264 - micro_f1s: 0.8264 - val_loss: 0.6159 - val_accuracy: 0.8100 - val_micro_f1s: 0.8149\n",
            "Epoch 131/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4689 - accuracy: 0.8324 - micro_f1s: 0.8324 - val_loss: 0.5181 - val_accuracy: 0.8500 - val_micro_f1s: 0.8486\n",
            "Epoch 132/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4717 - accuracy: 0.8337 - micro_f1s: 0.8337 - val_loss: 0.5407 - val_accuracy: 0.8575 - val_micro_f1s: 0.8606\n",
            "Epoch 133/150\n",
            "450/450 [==============================] - 17s 37ms/step - loss: 0.4653 - accuracy: 0.8351 - micro_f1s: 0.8351 - val_loss: 0.5433 - val_accuracy: 0.8350 - val_micro_f1s: 0.8389\n",
            "Epoch 134/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4788 - accuracy: 0.8323 - micro_f1s: 0.8323 - val_loss: 0.5022 - val_accuracy: 0.8600 - val_micro_f1s: 0.8606\n",
            "Epoch 135/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.5276 - accuracy: 0.8149 - micro_f1s: 0.8149 - val_loss: 0.4611 - val_accuracy: 0.8350 - val_micro_f1s: 0.8365\n",
            "Epoch 136/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4740 - accuracy: 0.8310 - micro_f1s: 0.8310 - val_loss: 0.6002 - val_accuracy: 0.8025 - val_micro_f1s: 0.8053\n",
            "Epoch 137/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4697 - accuracy: 0.8334 - micro_f1s: 0.8334 - val_loss: 0.6074 - val_accuracy: 0.8225 - val_micro_f1s: 0.8269\n",
            "Epoch 138/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4670 - accuracy: 0.8335 - micro_f1s: 0.8335 - val_loss: 0.5807 - val_accuracy: 0.8475 - val_micro_f1s: 0.8510\n",
            "Epoch 139/150\n",
            "450/450 [==============================] - 17s 37ms/step - loss: 0.4688 - accuracy: 0.8318 - micro_f1s: 0.8318 - val_loss: 0.5369 - val_accuracy: 0.8500 - val_micro_f1s: 0.8534\n",
            "Epoch 140/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4669 - accuracy: 0.8313 - micro_f1s: 0.8313 - val_loss: 0.4609 - val_accuracy: 0.8475 - val_micro_f1s: 0.8462\n",
            "Epoch 141/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4662 - accuracy: 0.8326 - micro_f1s: 0.8326 - val_loss: 0.5052 - val_accuracy: 0.8375 - val_micro_f1s: 0.8365\n",
            "Epoch 142/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4620 - accuracy: 0.8358 - micro_f1s: 0.8358 - val_loss: 0.5053 - val_accuracy: 0.8500 - val_micro_f1s: 0.8510\n",
            "Epoch 143/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4747 - accuracy: 0.8301 - micro_f1s: 0.8301 - val_loss: 0.5153 - val_accuracy: 0.8400 - val_micro_f1s: 0.8413\n",
            "Epoch 144/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4655 - accuracy: 0.8360 - micro_f1s: 0.8360 - val_loss: 0.5958 - val_accuracy: 0.8175 - val_micro_f1s: 0.8197\n",
            "Epoch 145/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4577 - accuracy: 0.8389 - micro_f1s: 0.8389 - val_loss: 0.5322 - val_accuracy: 0.8400 - val_micro_f1s: 0.8438\n",
            "Epoch 146/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4689 - accuracy: 0.8337 - micro_f1s: 0.8337 - val_loss: 0.5716 - val_accuracy: 0.8150 - val_micro_f1s: 0.8197\n",
            "Epoch 147/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4533 - accuracy: 0.8372 - micro_f1s: 0.8372 - val_loss: 0.4942 - val_accuracy: 0.8300 - val_micro_f1s: 0.8341\n",
            "Epoch 148/150\n",
            "450/450 [==============================] - 16s 35ms/step - loss: 0.4525 - accuracy: 0.8390 - micro_f1s: 0.8390 - val_loss: 0.4856 - val_accuracy: 0.8425 - val_micro_f1s: 0.8413\n",
            "Epoch 149/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4399 - accuracy: 0.8419 - micro_f1s: 0.8419 - val_loss: 0.5276 - val_accuracy: 0.8300 - val_micro_f1s: 0.8341\n",
            "Epoch 150/150\n",
            "450/450 [==============================] - 16s 36ms/step - loss: 0.4484 - accuracy: 0.8365 - micro_f1s: 0.8365 - val_loss: 0.5721 - val_accuracy: 0.8375 - val_micro_f1s: 0.8413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b6e365d50>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}